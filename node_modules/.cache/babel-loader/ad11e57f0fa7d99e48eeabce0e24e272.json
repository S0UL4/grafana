{"ast":null,"code":"function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nimport { clone, filter, find, identity, isArray, keys, map, uniq, values as _values } from 'lodash';\nimport { toDataFrame, FieldType, MutableDataFrame } from '@grafana/data';\nimport TableModel from 'app/core/table_model';\nimport flatten from 'app/core/utils/flatten';\nimport { isMetricAggregationWithField } from './components/QueryEditor/MetricAggregationsEditor/aggregations';\nimport { metricAggregationConfig } from './components/QueryEditor/MetricAggregationsEditor/utils';\nimport * as queryDef from './query_def';\nimport { describeMetric, getScriptValue } from './utils';\nconst HIGHLIGHT_TAGS_EXP = `${queryDef.highlightTags.pre}([^@]+)${queryDef.highlightTags.post}`;\nexport class ElasticResponse {\n  constructor(targets, _response) {\n    _defineProperty(this, \"processResponseToSeries\", () => {\n      const seriesList = [];\n\n      for (let i = 0; i < this.response.responses.length; i++) {\n        const response = this.response.responses[i];\n        const target = this.targets[i];\n\n        if (response.error) {\n          throw this.getErrorFromElasticResponse(this.response, response.error);\n        }\n\n        if (response.hits && response.hits.hits.length > 0) {\n          this.processHits(response.hits, seriesList, target);\n        }\n\n        if (response.aggregations) {\n          const aggregations = response.aggregations;\n          const target = this.targets[i];\n          const tmpSeriesList = [];\n          const table = new TableModel();\n          table.refId = target.refId;\n          this.processBuckets(aggregations, target, tmpSeriesList, table, {}, 0);\n          this.trimDatapoints(tmpSeriesList, target);\n          this.nameSeries(tmpSeriesList, target);\n\n          for (let y = 0; y < tmpSeriesList.length; y++) {\n            seriesList.push(tmpSeriesList[y]);\n          }\n\n          if (table.rows.length > 0) {\n            seriesList.push(table);\n          }\n        }\n      }\n\n      return {\n        data: seriesList\n      };\n    });\n\n    this.targets = targets;\n    this.response = _response;\n    this.targets = targets;\n    this.response = _response;\n  }\n\n  processMetrics(esAgg, target, seriesList, props) {\n    let newSeries;\n\n    for (let y = 0; y < target.metrics.length; y++) {\n      const metric = target.metrics[y];\n\n      if (metric.hide) {\n        continue;\n      }\n\n      switch (metric.type) {\n        case 'count':\n          {\n            newSeries = {\n              datapoints: [],\n              metric: 'count',\n              props,\n              refId: target.refId\n            };\n\n            for (let i = 0; i < esAgg.buckets.length; i++) {\n              const bucket = esAgg.buckets[i];\n              const value = bucket.doc_count;\n              newSeries.datapoints.push([value, bucket.key]);\n            }\n\n            seriesList.push(newSeries);\n            break;\n          }\n\n        case 'percentiles':\n          {\n            if (esAgg.buckets.length === 0) {\n              break;\n            }\n\n            const firstBucket = esAgg.buckets[0];\n            const percentiles = firstBucket[metric.id].values;\n\n            for (const percentileName in percentiles) {\n              newSeries = {\n                datapoints: [],\n                metric: 'p' + percentileName,\n                props: props,\n                field: metric.field,\n                refId: target.refId\n              };\n\n              for (let i = 0; i < esAgg.buckets.length; i++) {\n                const bucket = esAgg.buckets[i];\n                const values = bucket[metric.id].values;\n                newSeries.datapoints.push([values[percentileName], bucket.key]);\n              }\n\n              seriesList.push(newSeries);\n            }\n\n            break;\n          }\n\n        case 'extended_stats':\n          {\n            for (const statName in metric.meta) {\n              if (!metric.meta[statName]) {\n                continue;\n              }\n\n              newSeries = {\n                datapoints: [],\n                metric: statName,\n                props: props,\n                field: metric.field,\n                refId: target.refId\n              };\n\n              for (let i = 0; i < esAgg.buckets.length; i++) {\n                const bucket = esAgg.buckets[i];\n                const stats = bucket[metric.id]; // add stats that are in nested obj to top level obj\n\n                stats.std_deviation_bounds_upper = stats.std_deviation_bounds.upper;\n                stats.std_deviation_bounds_lower = stats.std_deviation_bounds.lower;\n                newSeries.datapoints.push([stats[statName], bucket.key]);\n              }\n\n              seriesList.push(newSeries);\n            }\n\n            break;\n          }\n\n        case 'top_metrics':\n          {\n            var _metric$settings, _metric$settings$metr;\n\n            if ((_metric$settings = metric.settings) !== null && _metric$settings !== void 0 && (_metric$settings$metr = _metric$settings.metrics) !== null && _metric$settings$metr !== void 0 && _metric$settings$metr.length) {\n              for (const metricField of (_metric$settings2 = metric.settings) === null || _metric$settings2 === void 0 ? void 0 : _metric$settings2.metrics) {\n                var _metric$settings2;\n\n                newSeries = {\n                  datapoints: [],\n                  metric: metric.type,\n                  props: props,\n                  refId: target.refId,\n                  field: metricField\n                };\n\n                for (let i = 0; i < esAgg.buckets.length; i++) {\n                  const bucket = esAgg.buckets[i];\n                  const stats = bucket[metric.id];\n                  const values = stats.top.map(hit => {\n                    if (hit.metrics[metricField]) {\n                      return hit.metrics[metricField];\n                    }\n\n                    return null;\n                  });\n                  const point = [values[values.length - 1], bucket.key];\n                  newSeries.datapoints.push(point);\n                }\n\n                seriesList.push(newSeries);\n              }\n            }\n\n            break;\n          }\n\n        default:\n          {\n            newSeries = {\n              datapoints: [],\n              metric: metric.type,\n              metricId: metric.id,\n              props: props,\n              refId: target.refId\n            };\n\n            if (isMetricAggregationWithField(metric)) {\n              newSeries.field = metric.field;\n            }\n\n            for (let i = 0; i < esAgg.buckets.length; i++) {\n              const bucket = esAgg.buckets[i];\n              const value = bucket[metric.id];\n\n              if (value !== undefined) {\n                if (value.normalized_value) {\n                  newSeries.datapoints.push([value.normalized_value, bucket.key]);\n                } else {\n                  newSeries.datapoints.push([value.value, bucket.key]);\n                }\n              }\n            }\n\n            seriesList.push(newSeries);\n            break;\n          }\n      }\n    }\n  }\n\n  processAggregationDocs(esAgg, aggDef, target, table, props) {\n    // add columns\n    if (table.columns.length === 0) {\n      for (const propKey of keys(props)) {\n        table.addColumn({\n          text: propKey,\n          filterable: true\n        });\n      }\n\n      table.addColumn({\n        text: aggDef.field,\n        filterable: true\n      });\n    } // helper func to add values to value array\n\n\n    const addMetricValue = (values, metricName, value) => {\n      table.addColumn({\n        text: metricName\n      });\n      values.push(value);\n    };\n\n    const buckets = isArray(esAgg.buckets) ? esAgg.buckets : [esAgg.buckets];\n\n    for (const bucket of buckets) {\n      const values = [];\n\n      for (const propValues of _values(props)) {\n        values.push(propValues);\n      } // add bucket key (value)\n\n\n      values.push(bucket.key);\n\n      for (const metric of target.metrics || []) {\n        switch (metric.type) {\n          case 'count':\n            {\n              addMetricValue(values, this.getMetricName(metric.type), bucket.doc_count);\n              break;\n            }\n\n          case 'extended_stats':\n            {\n              for (const statName in metric.meta) {\n                if (!metric.meta[statName]) {\n                  continue;\n                }\n\n                const stats = bucket[metric.id]; // add stats that are in nested obj to top level obj\n\n                stats.std_deviation_bounds_upper = stats.std_deviation_bounds.upper;\n                stats.std_deviation_bounds_lower = stats.std_deviation_bounds.lower;\n                addMetricValue(values, this.getMetricName(statName), stats[statName]);\n              }\n\n              break;\n            }\n\n          case 'percentiles':\n            {\n              const percentiles = bucket[metric.id].values;\n\n              for (const percentileName in percentiles) {\n                addMetricValue(values, `p${percentileName} ${metric.field}`, percentiles[percentileName]);\n              }\n\n              break;\n            }\n\n          case 'top_metrics':\n            {\n              var _metric$settings3;\n\n              const baseName = this.getMetricName(metric.type);\n\n              if ((_metric$settings3 = metric.settings) !== null && _metric$settings3 !== void 0 && _metric$settings3.metrics) {\n                for (const metricField of metric.settings.metrics) {\n                  // If we selected more than one metric we also add each metric name\n                  const metricName = metric.settings.metrics.length > 1 ? `${baseName} ${metricField}` : baseName;\n                  const stats = bucket[metric.id]; // Size of top_metrics is fixed to 1.\n\n                  addMetricValue(values, metricName, stats.top[0].metrics[metricField]);\n                }\n              }\n\n              break;\n            }\n\n          default:\n            {\n              let metricName = this.getMetricName(metric.type);\n              const otherMetrics = filter(target.metrics, {\n                type: metric.type\n              }); // if more of the same metric type include field field name in property\n\n              if (otherMetrics.length > 1) {\n                if (isMetricAggregationWithField(metric)) {\n                  metricName += ' ' + metric.field;\n                }\n\n                if (metric.type === 'bucket_script') {\n                  //Use the formula in the column name\n                  metricName = getScriptValue(metric);\n                }\n              }\n\n              addMetricValue(values, metricName, bucket[metric.id].value);\n              break;\n            }\n        }\n      }\n\n      table.rows.push(values);\n    }\n  } // This is quite complex\n  // need to recurse down the nested buckets to build series\n\n\n  processBuckets(aggs, target, seriesList, table, props, depth) {\n    let bucket, aggDef, esAgg, aggId;\n    const maxDepth = target.bucketAggs.length - 1;\n\n    for (aggId in aggs) {\n      aggDef = find(target.bucketAggs, {\n        id: aggId\n      });\n      esAgg = aggs[aggId];\n\n      if (!aggDef) {\n        continue;\n      }\n\n      if (depth === maxDepth) {\n        if (aggDef.type === 'date_histogram') {\n          this.processMetrics(esAgg, target, seriesList, props);\n        } else {\n          this.processAggregationDocs(esAgg, aggDef, target, table, props);\n        }\n      } else {\n        for (const nameIndex in esAgg.buckets) {\n          bucket = esAgg.buckets[nameIndex];\n          props = clone(props);\n\n          if (bucket.key !== void 0) {\n            props[aggDef.field] = bucket.key;\n          } else {\n            props['filter'] = nameIndex;\n          }\n\n          if (bucket.key_as_string) {\n            props[aggDef.field] = bucket.key_as_string;\n          }\n\n          this.processBuckets(bucket, target, seriesList, table, props, depth + 1);\n        }\n      }\n    }\n  }\n\n  getMetricName(metric) {\n    const metricDef = Object.entries(metricAggregationConfig).filter(([key]) => key === metric).map(([_, value]) => value)[0];\n\n    if (metricDef) {\n      return metricDef.label;\n    }\n\n    const extendedStat = queryDef.extendedStats.find(e => e.value === metric);\n\n    if (extendedStat) {\n      return extendedStat.label;\n    }\n\n    return metric;\n  }\n\n  getSeriesName(series, target, dedup) {\n    let metricName = this.getMetricName(series.metric);\n\n    if (target.alias) {\n      const regex = /\\{\\{([\\s\\S]+?)\\}\\}/g;\n      return target.alias.replace(regex, (match, g1, g2) => {\n        const group = g1 || g2;\n\n        if (group.indexOf('term ') === 0) {\n          return series.props[group.substring(5)];\n        }\n\n        if (series.props[group] !== void 0) {\n          return series.props[group];\n        }\n\n        if (group === 'metric') {\n          return metricName;\n        }\n\n        if (group === 'field') {\n          return series.field || '';\n        }\n\n        return match;\n      });\n    }\n\n    if (queryDef.isPipelineAgg(series.metric)) {\n      if (series.metric && queryDef.isPipelineAggWithMultipleBucketPaths(series.metric)) {\n        const agg = find(target.metrics, {\n          id: series.metricId\n        });\n\n        if (agg && agg.settings.script) {\n          metricName = getScriptValue(agg);\n\n          for (const pv of agg.pipelineVariables) {\n            const appliedAgg = find(target.metrics, {\n              id: pv.pipelineAgg\n            });\n\n            if (appliedAgg) {\n              metricName = metricName.replace('params.' + pv.name, describeMetric(appliedAgg));\n            }\n          }\n        } else {\n          metricName = 'Unset';\n        }\n      } else {\n        const appliedAgg = find(target.metrics, {\n          id: series.field\n        });\n\n        if (appliedAgg) {\n          metricName += ' ' + describeMetric(appliedAgg);\n        } else {\n          metricName = 'Unset';\n        }\n      }\n    } else if (series.field) {\n      metricName += ' ' + series.field;\n    }\n\n    const propKeys = keys(series.props);\n\n    if (propKeys.length === 0) {\n      return metricName;\n    }\n\n    let name = '';\n\n    for (const propName in series.props) {\n      name += series.props[propName] + ' ';\n    }\n\n    if (dedup) {\n      return name.trim() + ' ' + metricName;\n    }\n\n    return name.trim();\n  }\n\n  nameSeries(seriesList, target) {\n    var _target$metrics;\n\n    const metricTypeCount = uniq(map(seriesList, 'metric')).length;\n    const hasTopMetricWithMultipleMetrics = ((_target$metrics = target.metrics) === null || _target$metrics === void 0 ? void 0 : _target$metrics.filter(m => m.type === 'top_metrics')).some(m => {\n      var _m$settings, _m$settings$metrics;\n\n      return ((m === null || m === void 0 ? void 0 : (_m$settings = m.settings) === null || _m$settings === void 0 ? void 0 : (_m$settings$metrics = _m$settings.metrics) === null || _m$settings$metrics === void 0 ? void 0 : _m$settings$metrics.length) || 0) > 1;\n    });\n\n    for (let i = 0; i < seriesList.length; i++) {\n      const series = seriesList[i];\n      series.target = this.getSeriesName(series, target, metricTypeCount > 1 || hasTopMetricWithMultipleMetrics);\n    }\n  }\n\n  processHits(hits, seriesList, target) {\n    const hitsTotal = typeof hits.total === 'number' ? hits.total : hits.total.value; // <- Works with Elasticsearch 7.0+\n\n    const series = {\n      target: target.refId,\n      type: 'docs',\n      refId: target.refId,\n      datapoints: [],\n      total: hitsTotal,\n      filterable: true\n    };\n    let propName, hit, doc, i;\n\n    for (i = 0; i < hits.hits.length; i++) {\n      hit = hits.hits[i];\n      doc = {\n        _id: hit._id,\n        _type: hit._type,\n        _index: hit._index,\n        sort: hit.sort,\n        highlight: hit.highlight\n      };\n\n      if (hit._source) {\n        for (propName in hit._source) {\n          doc[propName] = hit._source[propName];\n        }\n      }\n\n      for (propName in hit.fields) {\n        doc[propName] = hit.fields[propName];\n      }\n\n      series.datapoints.push(doc);\n    }\n\n    seriesList.push(series);\n  }\n\n  trimDatapoints(aggregations, target) {\n    const histogram = find(target.bucketAggs, {\n      type: 'date_histogram'\n    });\n    const shouldDropFirstAndLast = histogram && histogram.settings && histogram.settings.trimEdges;\n\n    if (shouldDropFirstAndLast) {\n      const trim = histogram.settings.trimEdges;\n\n      for (const prop in aggregations) {\n        const points = aggregations[prop];\n\n        if (points.datapoints.length > trim * 2) {\n          points.datapoints = points.datapoints.slice(trim, points.datapoints.length - trim);\n        }\n      }\n    }\n  }\n\n  getErrorFromElasticResponse(response, err) {\n    const result = {};\n    result.data = JSON.stringify(err, null, 4);\n\n    if (err.root_cause && err.root_cause.length > 0 && err.root_cause[0].reason) {\n      result.message = err.root_cause[0].reason;\n    } else {\n      result.message = err.reason || 'Unknown elastic error response';\n    }\n\n    if (response.$$config) {\n      result.config = response.$$config;\n    }\n\n    return result;\n  }\n\n  getTimeSeries() {\n    if (this.targets.some(target => queryDef.hasMetricOfType(target, 'raw_data'))) {\n      return this.processResponseToDataFrames(false);\n    }\n\n    return this.processResponseToSeries();\n  }\n\n  getLogs(logMessageField, logLevelField) {\n    return this.processResponseToDataFrames(true, logMessageField, logLevelField);\n  }\n\n  processResponseToDataFrames(isLogsRequest, logMessageField, logLevelField) {\n    const dataFrame = [];\n\n    for (let n = 0; n < this.response.responses.length; n++) {\n      const response = this.response.responses[n];\n\n      if (response.error) {\n        throw this.getErrorFromElasticResponse(this.response, response.error);\n      }\n\n      if (response.hits) {\n        const {\n          propNames,\n          docs\n        } = flattenHits(response.hits.hits);\n        const series = docs.length ? createEmptyDataFrame(propNames.map(toNameTypePair(docs)), isLogsRequest, this.targets[0].timeField, logMessageField, logLevelField) : createEmptyDataFrame([], isLogsRequest);\n\n        if (isLogsRequest) {\n          addPreferredVisualisationType(series, 'logs');\n        } // Add a row for each document\n\n\n        for (const doc of docs) {\n          if (logLevelField) {\n            // Remap level field based on the datasource config. This field is\n            // then used in explore to figure out the log level. We may rewrite\n            // some actual data in the level field if they are different.\n            doc['level'] = doc[logLevelField];\n          } // When highlighting exists, we need to collect all the highlighted\n          // phrases and add them to the DataFrame's meta.searchWords array.\n\n\n          if (doc.highlight) {\n            var _series$meta;\n\n            // There might be multiple words so we need two versions of the\n            // regular expression. One to match gobally, when used with part.match,\n            // it returns and array of matches. The second one is used to capture the\n            // values between the tags.\n            const globalHighlightWordRegex = new RegExp(HIGHLIGHT_TAGS_EXP, 'g');\n            const highlightWordRegex = new RegExp(HIGHLIGHT_TAGS_EXP);\n            const newSearchWords = Object.keys(doc.highlight).flatMap(key => {\n              return doc.highlight[key].flatMap(line => {\n                const matchedPhrases = line.match(globalHighlightWordRegex);\n\n                if (!matchedPhrases) {\n                  return [];\n                }\n\n                return matchedPhrases.map(part => {\n                  const matches = part.match(highlightWordRegex);\n                  return matches && matches[1] || null;\n                });\n              });\n            }).filter(identity); // If meta and searchWords already exists, add the words and\n            // deduplicate otherwise create a new set of search words.\n\n            const searchWords = (_series$meta = series.meta) !== null && _series$meta !== void 0 && _series$meta.searchWords ? uniq([...series.meta.searchWords, ...newSearchWords]) : [...newSearchWords];\n            series.meta = series.meta ? Object.assign({}, series.meta, {\n              searchWords\n            }) : {\n              searchWords\n            };\n          }\n\n          series.add(doc);\n        }\n\n        const target = this.targets[n];\n        series.refId = target.refId;\n        dataFrame.push(series);\n      }\n\n      if (response.aggregations) {\n        const aggregations = response.aggregations;\n        const target = this.targets[n];\n        const tmpSeriesList = [];\n        const table = new TableModel();\n        this.processBuckets(aggregations, target, tmpSeriesList, table, {}, 0);\n        this.trimDatapoints(tmpSeriesList, target);\n        this.nameSeries(tmpSeriesList, target);\n\n        if (table.rows.length > 0) {\n          const series = toDataFrame(table);\n          series.refId = target.refId;\n          dataFrame.push(series);\n        }\n\n        for (let y = 0; y < tmpSeriesList.length; y++) {\n          let series = toDataFrame(tmpSeriesList[y]); // When log results, show aggregations only in graph. Log fields are then going to be shown in table.\n\n          if (isLogsRequest) {\n            addPreferredVisualisationType(series, 'graph');\n          }\n\n          series.refId = target.refId;\n          dataFrame.push(series);\n        }\n      }\n    }\n\n    return {\n      data: dataFrame\n    };\n  }\n\n}\n\n/**\n * Flatten the docs from response mainly the _source part which can be nested. This flattens it so that it is one level\n * deep and the keys are: `level1Name.level2Name...`. Also returns list of all properties from all the docs (not all\n * docs have to have the same keys).\n * @param hits\n */\nconst flattenHits = hits => {\n  const docs = []; // We keep a list of all props so that we can create all the fields in the dataFrame, this can lead\n  // to wide sparse dataframes in case the scheme is different per document.\n\n  let propNames = [];\n\n  for (const hit of hits) {\n    const flattened = hit._source ? flatten(hit._source) : {};\n    const doc = Object.assign({\n      _id: hit._id,\n      _type: hit._type,\n      _index: hit._index,\n      sort: hit.sort,\n      highlight: hit.highlight,\n      _source: Object.assign({}, flattened)\n    }, flattened);\n\n    for (const propName of Object.keys(doc)) {\n      if (propNames.indexOf(propName) === -1) {\n        propNames.push(propName);\n      }\n    }\n\n    docs.push(doc);\n  }\n\n  propNames.sort();\n  return {\n    docs,\n    propNames\n  };\n};\n/**\n * Create empty dataframe but with created fields. Fields are based from propNames (should be from the response) and\n * also from configuration specified fields for message, time, and level.\n * @param propNames\n * @param timeField\n * @param logMessageField\n * @param logLevelField\n */\n\n\nconst createEmptyDataFrame = (props, isLogsRequest, timeField, logMessageField, logLevelField) => {\n  const series = new MutableDataFrame({\n    fields: []\n  });\n\n  if (timeField) {\n    series.addField({\n      config: {\n        filterable: true\n      },\n      name: timeField,\n      type: FieldType.time\n    });\n  }\n\n  if (logMessageField) {\n    const f = series.addField({\n      name: logMessageField,\n      type: FieldType.string\n    });\n    series.setParser(f, v => {\n      return v || '';\n    });\n  }\n\n  if (logLevelField) {\n    const f = series.addField({\n      name: 'level',\n      type: FieldType.string\n    });\n    series.setParser(f, v => {\n      return v || '';\n    });\n  }\n\n  const fieldNames = series.fields.map(field => field.name);\n\n  for (const [name, type] of props) {\n    // Do not duplicate fields. This can mean that we will shadow some fields.\n    if (fieldNames.includes(name)) {\n      continue;\n    } // Do not add _source field (besides logs) as we are showing each _source field in table instead.\n\n\n    if (!isLogsRequest && name === '_source') {\n      continue;\n    }\n\n    const f = series.addField({\n      config: {\n        filterable: true\n      },\n      name,\n      type\n    });\n    series.setParser(f, v => {\n      return v || '';\n    });\n  }\n\n  return series;\n};\n\nconst addPreferredVisualisationType = (series, type) => {\n  let s = series;\n  s.meta ? s.meta.preferredVisualisationType = type : s.meta = {\n    preferredVisualisationType: type\n  };\n};\n\nconst toNameTypePair = docs => propName => {\n  var _docs$find;\n\n  return [propName, guessType((_docs$find = docs.find(doc => doc[propName] !== undefined)) === null || _docs$find === void 0 ? void 0 : _docs$find[propName])];\n};\n/**\n * Trying to guess data type from its value. This is far from perfect, as in order to have accurate guess\n * we should have access to the elasticsearch mapping, but it covers the most common use cases for numbers, strings & arrays.\n */\n\n\nconst guessType = value => {\n  switch (typeof value) {\n    case 'number':\n      return FieldType.number;\n\n    case 'string':\n      return FieldType.string;\n\n    default:\n      return FieldType.other;\n  }\n};","map":{"version":3,"names":["clone","filter","find","identity","isArray","keys","map","uniq","values","_values","toDataFrame","FieldType","MutableDataFrame","TableModel","flatten","isMetricAggregationWithField","metricAggregationConfig","queryDef","describeMetric","getScriptValue","HIGHLIGHT_TAGS_EXP","highlightTags","pre","post","ElasticResponse","constructor","targets","response","seriesList","i","responses","length","target","error","getErrorFromElasticResponse","hits","processHits","aggregations","tmpSeriesList","table","refId","processBuckets","trimDatapoints","nameSeries","y","push","rows","data","processMetrics","esAgg","props","newSeries","metrics","metric","hide","type","datapoints","buckets","bucket","value","doc_count","key","firstBucket","percentiles","id","percentileName","field","statName","meta","stats","std_deviation_bounds_upper","std_deviation_bounds","upper","std_deviation_bounds_lower","lower","settings","metricField","top","hit","point","metricId","undefined","normalized_value","processAggregationDocs","aggDef","columns","propKey","addColumn","text","filterable","addMetricValue","metricName","propValues","getMetricName","baseName","otherMetrics","aggs","depth","aggId","maxDepth","bucketAggs","nameIndex","key_as_string","metricDef","Object","entries","_","label","extendedStat","extendedStats","e","getSeriesName","series","dedup","alias","regex","replace","match","g1","g2","group","indexOf","substring","isPipelineAgg","isPipelineAggWithMultipleBucketPaths","agg","script","pv","pipelineVariables","appliedAgg","pipelineAgg","name","propKeys","propName","trim","metricTypeCount","hasTopMetricWithMultipleMetrics","m","some","hitsTotal","total","doc","_id","_type","_index","sort","highlight","_source","fields","histogram","shouldDropFirstAndLast","trimEdges","prop","points","slice","err","result","JSON","stringify","root_cause","reason","message","$$config","config","getTimeSeries","hasMetricOfType","processResponseToDataFrames","processResponseToSeries","getLogs","logMessageField","logLevelField","isLogsRequest","dataFrame","n","propNames","docs","flattenHits","createEmptyDataFrame","toNameTypePair","timeField","addPreferredVisualisationType","globalHighlightWordRegex","RegExp","highlightWordRegex","newSearchWords","flatMap","line","matchedPhrases","part","matches","searchWords","add","flattened","addField","time","f","string","setParser","v","fieldNames","includes","s","preferredVisualisationType","guessType","number","other"],"sources":["/home/soula/grafana/public/app/plugins/datasource/elasticsearch/elastic_response.ts"],"sourcesContent":["import { clone, filter, find, identity, isArray, keys, map, uniq, values as _values } from 'lodash';\n\nimport {\n  DataQueryResponse,\n  DataFrame,\n  toDataFrame,\n  FieldType,\n  MutableDataFrame,\n  PreferredVisualisationType,\n} from '@grafana/data';\nimport TableModel from 'app/core/table_model';\nimport flatten from 'app/core/utils/flatten';\n\nimport {\n  ExtendedStatMetaType,\n  isMetricAggregationWithField,\n  TopMetrics,\n} from './components/QueryEditor/MetricAggregationsEditor/aggregations';\nimport { metricAggregationConfig } from './components/QueryEditor/MetricAggregationsEditor/utils';\nimport * as queryDef from './query_def';\nimport { ElasticsearchAggregation, ElasticsearchQuery } from './types';\nimport { describeMetric, getScriptValue } from './utils';\n\nconst HIGHLIGHT_TAGS_EXP = `${queryDef.highlightTags.pre}([^@]+)${queryDef.highlightTags.post}`;\ntype TopMetricMetric = Record<string, number>;\ninterface TopMetricBucket {\n  top: Array<{\n    metrics: TopMetricMetric;\n  }>;\n}\n\nexport class ElasticResponse {\n  constructor(private targets: ElasticsearchQuery[], private response: any) {\n    this.targets = targets;\n    this.response = response;\n  }\n\n  processMetrics(esAgg: any, target: ElasticsearchQuery, seriesList: any, props: any) {\n    let newSeries: any;\n\n    for (let y = 0; y < target.metrics!.length; y++) {\n      const metric = target.metrics![y];\n      if (metric.hide) {\n        continue;\n      }\n\n      switch (metric.type) {\n        case 'count': {\n          newSeries = { datapoints: [], metric: 'count', props, refId: target.refId };\n          for (let i = 0; i < esAgg.buckets.length; i++) {\n            const bucket = esAgg.buckets[i];\n            const value = bucket.doc_count;\n            newSeries.datapoints.push([value, bucket.key]);\n          }\n          seriesList.push(newSeries);\n          break;\n        }\n        case 'percentiles': {\n          if (esAgg.buckets.length === 0) {\n            break;\n          }\n\n          const firstBucket = esAgg.buckets[0];\n          const percentiles = firstBucket[metric.id].values;\n\n          for (const percentileName in percentiles) {\n            newSeries = {\n              datapoints: [],\n              metric: 'p' + percentileName,\n              props: props,\n              field: metric.field,\n              refId: target.refId,\n            };\n\n            for (let i = 0; i < esAgg.buckets.length; i++) {\n              const bucket = esAgg.buckets[i];\n              const values = bucket[metric.id].values;\n              newSeries.datapoints.push([values[percentileName], bucket.key]);\n            }\n            seriesList.push(newSeries);\n          }\n\n          break;\n        }\n        case 'extended_stats': {\n          for (const statName in metric.meta) {\n            if (!metric.meta[statName as ExtendedStatMetaType]) {\n              continue;\n            }\n\n            newSeries = {\n              datapoints: [],\n              metric: statName,\n              props: props,\n              field: metric.field,\n              refId: target.refId,\n            };\n\n            for (let i = 0; i < esAgg.buckets.length; i++) {\n              const bucket = esAgg.buckets[i];\n              const stats = bucket[metric.id];\n\n              // add stats that are in nested obj to top level obj\n              stats.std_deviation_bounds_upper = stats.std_deviation_bounds.upper;\n              stats.std_deviation_bounds_lower = stats.std_deviation_bounds.lower;\n\n              newSeries.datapoints.push([stats[statName], bucket.key]);\n            }\n\n            seriesList.push(newSeries);\n          }\n\n          break;\n        }\n        case 'top_metrics': {\n          if (metric.settings?.metrics?.length) {\n            for (const metricField of metric.settings?.metrics) {\n              newSeries = {\n                datapoints: [],\n                metric: metric.type,\n                props: props,\n                refId: target.refId,\n                field: metricField,\n              };\n              for (let i = 0; i < esAgg.buckets.length; i++) {\n                const bucket = esAgg.buckets[i];\n                const stats = bucket[metric.id] as TopMetricBucket;\n                const values = stats.top.map((hit) => {\n                  if (hit.metrics[metricField]) {\n                    return hit.metrics[metricField];\n                  }\n                  return null;\n                });\n                const point = [values[values.length - 1], bucket.key];\n                newSeries.datapoints.push(point);\n              }\n              seriesList.push(newSeries);\n            }\n          }\n          break;\n        }\n        default: {\n          newSeries = {\n            datapoints: [],\n            metric: metric.type,\n            metricId: metric.id,\n            props: props,\n            refId: target.refId,\n          };\n\n          if (isMetricAggregationWithField(metric)) {\n            newSeries.field = metric.field;\n          }\n\n          for (let i = 0; i < esAgg.buckets.length; i++) {\n            const bucket = esAgg.buckets[i];\n            const value = bucket[metric.id];\n\n            if (value !== undefined) {\n              if (value.normalized_value) {\n                newSeries.datapoints.push([value.normalized_value, bucket.key]);\n              } else {\n                newSeries.datapoints.push([value.value, bucket.key]);\n              }\n            }\n          }\n          seriesList.push(newSeries);\n          break;\n        }\n      }\n    }\n  }\n\n  processAggregationDocs(\n    esAgg: any,\n    aggDef: ElasticsearchAggregation,\n    target: ElasticsearchQuery,\n    table: any,\n    props: any\n  ) {\n    // add columns\n    if (table.columns.length === 0) {\n      for (const propKey of keys(props)) {\n        table.addColumn({ text: propKey, filterable: true });\n      }\n      table.addColumn({ text: aggDef.field, filterable: true });\n    }\n\n    // helper func to add values to value array\n    const addMetricValue = (values: any[], metricName: string, value: any) => {\n      table.addColumn({ text: metricName });\n      values.push(value);\n    };\n    const buckets = isArray(esAgg.buckets) ? esAgg.buckets : [esAgg.buckets];\n    for (const bucket of buckets) {\n      const values = [];\n\n      for (const propValues of _values(props)) {\n        values.push(propValues);\n      }\n\n      // add bucket key (value)\n      values.push(bucket.key);\n\n      for (const metric of target.metrics || []) {\n        switch (metric.type) {\n          case 'count': {\n            addMetricValue(values, this.getMetricName(metric.type), bucket.doc_count);\n            break;\n          }\n          case 'extended_stats': {\n            for (const statName in metric.meta) {\n              if (!metric.meta[statName as ExtendedStatMetaType]) {\n                continue;\n              }\n\n              const stats = bucket[metric.id];\n              // add stats that are in nested obj to top level obj\n              stats.std_deviation_bounds_upper = stats.std_deviation_bounds.upper;\n              stats.std_deviation_bounds_lower = stats.std_deviation_bounds.lower;\n\n              addMetricValue(values, this.getMetricName(statName as ExtendedStatMetaType), stats[statName]);\n            }\n            break;\n          }\n          case 'percentiles': {\n            const percentiles = bucket[metric.id].values;\n\n            for (const percentileName in percentiles) {\n              addMetricValue(values, `p${percentileName} ${metric.field}`, percentiles[percentileName]);\n            }\n            break;\n          }\n          case 'top_metrics': {\n            const baseName = this.getMetricName(metric.type);\n\n            if (metric.settings?.metrics) {\n              for (const metricField of metric.settings.metrics) {\n                // If we selected more than one metric we also add each metric name\n                const metricName = metric.settings.metrics.length > 1 ? `${baseName} ${metricField}` : baseName;\n\n                const stats = bucket[metric.id] as TopMetricBucket;\n\n                // Size of top_metrics is fixed to 1.\n                addMetricValue(values, metricName, stats.top[0].metrics[metricField]);\n              }\n            }\n\n            break;\n          }\n          default: {\n            let metricName = this.getMetricName(metric.type);\n            const otherMetrics = filter(target.metrics, { type: metric.type });\n\n            // if more of the same metric type include field field name in property\n            if (otherMetrics.length > 1) {\n              if (isMetricAggregationWithField(metric)) {\n                metricName += ' ' + metric.field;\n              }\n\n              if (metric.type === 'bucket_script') {\n                //Use the formula in the column name\n                metricName = getScriptValue(metric);\n              }\n            }\n\n            addMetricValue(values, metricName, bucket[metric.id].value);\n            break;\n          }\n        }\n      }\n\n      table.rows.push(values);\n    }\n  }\n\n  // This is quite complex\n  // need to recurse down the nested buckets to build series\n  processBuckets(aggs: any, target: ElasticsearchQuery, seriesList: any, table: TableModel, props: any, depth: number) {\n    let bucket, aggDef: any, esAgg, aggId;\n    const maxDepth = target.bucketAggs!.length - 1;\n\n    for (aggId in aggs) {\n      aggDef = find(target.bucketAggs, { id: aggId });\n      esAgg = aggs[aggId];\n\n      if (!aggDef) {\n        continue;\n      }\n\n      if (depth === maxDepth) {\n        if (aggDef.type === 'date_histogram') {\n          this.processMetrics(esAgg, target, seriesList, props);\n        } else {\n          this.processAggregationDocs(esAgg, aggDef, target, table, props);\n        }\n      } else {\n        for (const nameIndex in esAgg.buckets) {\n          bucket = esAgg.buckets[nameIndex];\n          props = clone(props);\n          if (bucket.key !== void 0) {\n            props[aggDef.field] = bucket.key;\n          } else {\n            props['filter'] = nameIndex;\n          }\n          if (bucket.key_as_string) {\n            props[aggDef.field] = bucket.key_as_string;\n          }\n          this.processBuckets(bucket, target, seriesList, table, props, depth + 1);\n        }\n      }\n    }\n  }\n\n  private getMetricName(metric: string): string {\n    const metricDef = Object.entries(metricAggregationConfig)\n      .filter(([key]) => key === metric)\n      .map(([_, value]) => value)[0];\n\n    if (metricDef) {\n      return metricDef.label;\n    }\n\n    const extendedStat = queryDef.extendedStats.find((e) => e.value === metric);\n    if (extendedStat) {\n      return extendedStat.label;\n    }\n\n    return metric;\n  }\n\n  private getSeriesName(series: any, target: ElasticsearchQuery, dedup: boolean) {\n    let metricName = this.getMetricName(series.metric);\n\n    if (target.alias) {\n      const regex = /\\{\\{([\\s\\S]+?)\\}\\}/g;\n\n      return target.alias.replace(regex, (match: any, g1: any, g2: any) => {\n        const group = g1 || g2;\n\n        if (group.indexOf('term ') === 0) {\n          return series.props[group.substring(5)];\n        }\n        if (series.props[group] !== void 0) {\n          return series.props[group];\n        }\n        if (group === 'metric') {\n          return metricName;\n        }\n        if (group === 'field') {\n          return series.field || '';\n        }\n\n        return match;\n      });\n    }\n\n    if (queryDef.isPipelineAgg(series.metric)) {\n      if (series.metric && queryDef.isPipelineAggWithMultipleBucketPaths(series.metric)) {\n        const agg: any = find(target.metrics, { id: series.metricId });\n        if (agg && agg.settings.script) {\n          metricName = getScriptValue(agg);\n\n          for (const pv of agg.pipelineVariables) {\n            const appliedAgg: any = find(target.metrics, { id: pv.pipelineAgg });\n            if (appliedAgg) {\n              metricName = metricName.replace('params.' + pv.name, describeMetric(appliedAgg));\n            }\n          }\n        } else {\n          metricName = 'Unset';\n        }\n      } else {\n        const appliedAgg: any = find(target.metrics, { id: series.field });\n        if (appliedAgg) {\n          metricName += ' ' + describeMetric(appliedAgg);\n        } else {\n          metricName = 'Unset';\n        }\n      }\n    } else if (series.field) {\n      metricName += ' ' + series.field;\n    }\n\n    const propKeys = keys(series.props);\n    if (propKeys.length === 0) {\n      return metricName;\n    }\n\n    let name = '';\n    for (const propName in series.props) {\n      name += series.props[propName] + ' ';\n    }\n\n    if (dedup) {\n      return name.trim() + ' ' + metricName;\n    }\n\n    return name.trim();\n  }\n\n  nameSeries(seriesList: any, target: ElasticsearchQuery) {\n    const metricTypeCount = uniq(map(seriesList, 'metric')).length;\n    const hasTopMetricWithMultipleMetrics = (\n      target.metrics?.filter((m) => m.type === 'top_metrics') as TopMetrics[]\n    ).some((m) => (m?.settings?.metrics?.length || 0) > 1);\n\n    for (let i = 0; i < seriesList.length; i++) {\n      const series = seriesList[i];\n      series.target = this.getSeriesName(series, target, metricTypeCount > 1 || hasTopMetricWithMultipleMetrics);\n    }\n  }\n\n  processHits(hits: { total: { value: any }; hits: any[] }, seriesList: any[], target: ElasticsearchQuery) {\n    const hitsTotal = typeof hits.total === 'number' ? hits.total : hits.total.value; // <- Works with Elasticsearch 7.0+\n\n    const series: any = {\n      target: target.refId,\n      type: 'docs',\n      refId: target.refId,\n      datapoints: [],\n      total: hitsTotal,\n      filterable: true,\n    };\n    let propName, hit, doc: any, i;\n\n    for (i = 0; i < hits.hits.length; i++) {\n      hit = hits.hits[i];\n      doc = {\n        _id: hit._id,\n        _type: hit._type,\n        _index: hit._index,\n        sort: hit.sort,\n        highlight: hit.highlight,\n      };\n\n      if (hit._source) {\n        for (propName in hit._source) {\n          doc[propName] = hit._source[propName];\n        }\n      }\n\n      for (propName in hit.fields) {\n        doc[propName] = hit.fields[propName];\n      }\n      series.datapoints.push(doc);\n    }\n\n    seriesList.push(series);\n  }\n\n  trimDatapoints(aggregations: any, target: ElasticsearchQuery) {\n    const histogram: any = find(target.bucketAggs, { type: 'date_histogram' });\n\n    const shouldDropFirstAndLast = histogram && histogram.settings && histogram.settings.trimEdges;\n    if (shouldDropFirstAndLast) {\n      const trim = histogram.settings.trimEdges;\n      for (const prop in aggregations) {\n        const points = aggregations[prop];\n        if (points.datapoints.length > trim * 2) {\n          points.datapoints = points.datapoints.slice(trim, points.datapoints.length - trim);\n        }\n      }\n    }\n  }\n\n  getErrorFromElasticResponse(response: any, err: any) {\n    const result: any = {};\n    result.data = JSON.stringify(err, null, 4);\n    if (err.root_cause && err.root_cause.length > 0 && err.root_cause[0].reason) {\n      result.message = err.root_cause[0].reason;\n    } else {\n      result.message = err.reason || 'Unknown elastic error response';\n    }\n\n    if (response.$$config) {\n      result.config = response.$$config;\n    }\n\n    return result;\n  }\n\n  getTimeSeries() {\n    if (this.targets.some((target) => queryDef.hasMetricOfType(target, 'raw_data'))) {\n      return this.processResponseToDataFrames(false);\n    }\n    return this.processResponseToSeries();\n  }\n\n  getLogs(logMessageField?: string, logLevelField?: string): DataQueryResponse {\n    return this.processResponseToDataFrames(true, logMessageField, logLevelField);\n  }\n\n  private processResponseToDataFrames(\n    isLogsRequest: boolean,\n    logMessageField?: string,\n    logLevelField?: string\n  ): DataQueryResponse {\n    const dataFrame: DataFrame[] = [];\n    for (let n = 0; n < this.response.responses.length; n++) {\n      const response = this.response.responses[n];\n      if (response.error) {\n        throw this.getErrorFromElasticResponse(this.response, response.error);\n      }\n\n      if (response.hits) {\n        const { propNames, docs } = flattenHits(response.hits.hits);\n\n        const series = docs.length\n          ? createEmptyDataFrame(\n              propNames.map(toNameTypePair(docs)),\n              isLogsRequest,\n              this.targets[0].timeField,\n              logMessageField,\n              logLevelField\n            )\n          : createEmptyDataFrame([], isLogsRequest);\n\n        if (isLogsRequest) {\n          addPreferredVisualisationType(series, 'logs');\n        }\n\n        // Add a row for each document\n        for (const doc of docs) {\n          if (logLevelField) {\n            // Remap level field based on the datasource config. This field is\n            // then used in explore to figure out the log level. We may rewrite\n            // some actual data in the level field if they are different.\n            doc['level'] = doc[logLevelField];\n          }\n          // When highlighting exists, we need to collect all the highlighted\n          // phrases and add them to the DataFrame's meta.searchWords array.\n          if (doc.highlight) {\n            // There might be multiple words so we need two versions of the\n            // regular expression. One to match gobally, when used with part.match,\n            // it returns and array of matches. The second one is used to capture the\n            // values between the tags.\n            const globalHighlightWordRegex = new RegExp(HIGHLIGHT_TAGS_EXP, 'g');\n            const highlightWordRegex = new RegExp(HIGHLIGHT_TAGS_EXP);\n            const newSearchWords = Object.keys(doc.highlight)\n              .flatMap((key) => {\n                return doc.highlight[key].flatMap((line: string) => {\n                  const matchedPhrases = line.match(globalHighlightWordRegex);\n                  if (!matchedPhrases) {\n                    return [];\n                  }\n                  return matchedPhrases.map((part) => {\n                    const matches = part.match(highlightWordRegex);\n                    return (matches && matches[1]) || null;\n                  });\n                });\n              })\n              .filter(identity);\n            // If meta and searchWords already exists, add the words and\n            // deduplicate otherwise create a new set of search words.\n            const searchWords = series.meta?.searchWords\n              ? uniq([...series.meta.searchWords, ...newSearchWords])\n              : [...newSearchWords];\n            series.meta = series.meta ? { ...series.meta, searchWords } : { searchWords };\n          }\n          series.add(doc);\n        }\n\n        const target = this.targets[n];\n        series.refId = target.refId;\n        dataFrame.push(series);\n      }\n\n      if (response.aggregations) {\n        const aggregations = response.aggregations;\n        const target = this.targets[n];\n        const tmpSeriesList: any[] = [];\n        const table = new TableModel();\n\n        this.processBuckets(aggregations, target, tmpSeriesList, table, {}, 0);\n        this.trimDatapoints(tmpSeriesList, target);\n        this.nameSeries(tmpSeriesList, target);\n\n        if (table.rows.length > 0) {\n          const series = toDataFrame(table);\n          series.refId = target.refId;\n          dataFrame.push(series);\n        }\n\n        for (let y = 0; y < tmpSeriesList.length; y++) {\n          let series = toDataFrame(tmpSeriesList[y]);\n\n          // When log results, show aggregations only in graph. Log fields are then going to be shown in table.\n          if (isLogsRequest) {\n            addPreferredVisualisationType(series, 'graph');\n          }\n\n          series.refId = target.refId;\n          dataFrame.push(series);\n        }\n      }\n    }\n\n    return { data: dataFrame };\n  }\n\n  processResponseToSeries = () => {\n    const seriesList = [];\n\n    for (let i = 0; i < this.response.responses.length; i++) {\n      const response = this.response.responses[i];\n      const target = this.targets[i];\n\n      if (response.error) {\n        throw this.getErrorFromElasticResponse(this.response, response.error);\n      }\n\n      if (response.hits && response.hits.hits.length > 0) {\n        this.processHits(response.hits, seriesList, target);\n      }\n\n      if (response.aggregations) {\n        const aggregations = response.aggregations;\n        const target = this.targets[i];\n        const tmpSeriesList: any[] = [];\n        const table = new TableModel();\n        table.refId = target.refId;\n\n        this.processBuckets(aggregations, target, tmpSeriesList, table, {}, 0);\n        this.trimDatapoints(tmpSeriesList, target);\n        this.nameSeries(tmpSeriesList, target);\n\n        for (let y = 0; y < tmpSeriesList.length; y++) {\n          seriesList.push(tmpSeriesList[y]);\n        }\n\n        if (table.rows.length > 0) {\n          seriesList.push(table);\n        }\n      }\n    }\n\n    return { data: seriesList };\n  };\n}\n\ntype Doc = {\n  _id: string;\n  _type: string;\n  _index: string;\n  _source?: any;\n  sort?: Array<string | number>;\n  highlight?: Record<string, string[]>;\n};\n\n/**\n * Flatten the docs from response mainly the _source part which can be nested. This flattens it so that it is one level\n * deep and the keys are: `level1Name.level2Name...`. Also returns list of all properties from all the docs (not all\n * docs have to have the same keys).\n * @param hits\n */\nconst flattenHits = (hits: Doc[]): { docs: Array<Record<string, any>>; propNames: string[] } => {\n  const docs: any[] = [];\n  // We keep a list of all props so that we can create all the fields in the dataFrame, this can lead\n  // to wide sparse dataframes in case the scheme is different per document.\n  let propNames: string[] = [];\n\n  for (const hit of hits) {\n    const flattened = hit._source ? flatten(hit._source) : {};\n    const doc = {\n      _id: hit._id,\n      _type: hit._type,\n      _index: hit._index,\n      sort: hit.sort,\n      highlight: hit.highlight,\n      _source: { ...flattened },\n      ...flattened,\n    };\n\n    for (const propName of Object.keys(doc)) {\n      if (propNames.indexOf(propName) === -1) {\n        propNames.push(propName);\n      }\n    }\n\n    docs.push(doc);\n  }\n\n  propNames.sort();\n  return { docs, propNames };\n};\n\n/**\n * Create empty dataframe but with created fields. Fields are based from propNames (should be from the response) and\n * also from configuration specified fields for message, time, and level.\n * @param propNames\n * @param timeField\n * @param logMessageField\n * @param logLevelField\n */\nconst createEmptyDataFrame = (\n  props: Array<[string, FieldType]>,\n  isLogsRequest: boolean,\n  timeField?: string,\n  logMessageField?: string,\n  logLevelField?: string\n): MutableDataFrame => {\n  const series = new MutableDataFrame({ fields: [] });\n\n  if (timeField) {\n    series.addField({\n      config: {\n        filterable: true,\n      },\n      name: timeField,\n      type: FieldType.time,\n    });\n  }\n\n  if (logMessageField) {\n    const f = series.addField({\n      name: logMessageField,\n      type: FieldType.string,\n    });\n    series.setParser(f, (v: any) => {\n      return v || '';\n    });\n  }\n\n  if (logLevelField) {\n    const f = series.addField({\n      name: 'level',\n      type: FieldType.string,\n    });\n    series.setParser(f, (v: any) => {\n      return v || '';\n    });\n  }\n\n  const fieldNames = series.fields.map((field) => field.name);\n\n  for (const [name, type] of props) {\n    // Do not duplicate fields. This can mean that we will shadow some fields.\n    if (fieldNames.includes(name)) {\n      continue;\n    }\n    // Do not add _source field (besides logs) as we are showing each _source field in table instead.\n    if (!isLogsRequest && name === '_source') {\n      continue;\n    }\n\n    const f = series.addField({\n      config: {\n        filterable: true,\n      },\n      name,\n      type,\n    });\n    series.setParser(f, (v: any) => {\n      return v || '';\n    });\n  }\n\n  return series;\n};\n\nconst addPreferredVisualisationType = (series: any, type: PreferredVisualisationType) => {\n  let s = series;\n  s.meta\n    ? (s.meta.preferredVisualisationType = type)\n    : (s.meta = {\n        preferredVisualisationType: type,\n      });\n};\n\nconst toNameTypePair =\n  (docs: Array<Record<string, any>>) =>\n  (propName: string): [string, FieldType] =>\n    [propName, guessType(docs.find((doc) => doc[propName] !== undefined)?.[propName])];\n\n/**\n * Trying to guess data type from its value. This is far from perfect, as in order to have accurate guess\n * we should have access to the elasticsearch mapping, but it covers the most common use cases for numbers, strings & arrays.\n */\nconst guessType = (value: unknown): FieldType => {\n  switch (typeof value) {\n    case 'number':\n      return FieldType.number;\n    case 'string':\n      return FieldType.string;\n    default:\n      return FieldType.other;\n  }\n};\n"],"mappings":";;AAAA,SAASA,KAAT,EAAgBC,MAAhB,EAAwBC,IAAxB,EAA8BC,QAA9B,EAAwCC,OAAxC,EAAiDC,IAAjD,EAAuDC,GAAvD,EAA4DC,IAA5D,EAAkEC,MAAM,IAAIC,OAA5E,QAA2F,QAA3F;AAEA,SAGEC,WAHF,EAIEC,SAJF,EAKEC,gBALF,QAOO,eAPP;AAQA,OAAOC,UAAP,MAAuB,sBAAvB;AACA,OAAOC,OAAP,MAAoB,wBAApB;AAEA,SAEEC,4BAFF,QAIO,gEAJP;AAKA,SAASC,uBAAT,QAAwC,yDAAxC;AACA,OAAO,KAAKC,QAAZ,MAA0B,aAA1B;AAEA,SAASC,cAAT,EAAyBC,cAAzB,QAA+C,SAA/C;AAEA,MAAMC,kBAAkB,GAAI,GAAEH,QAAQ,CAACI,aAAT,CAAuBC,GAAI,UAASL,QAAQ,CAACI,aAAT,CAAuBE,IAAK,EAA9F;AAQA,OAAO,MAAMC,eAAN,CAAsB;EAC3BC,WAAW,CAASC,OAAT,EAAgDC,SAAhD,EAA+D;IAAA,iDAyjBhD,MAAM;MAC9B,MAAMC,UAAU,GAAG,EAAnB;;MAEA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKF,QAAL,CAAcG,SAAd,CAAwBC,MAA5C,EAAoDF,CAAC,EAArD,EAAyD;QACvD,MAAMF,QAAQ,GAAG,KAAKA,QAAL,CAAcG,SAAd,CAAwBD,CAAxB,CAAjB;QACA,MAAMG,MAAM,GAAG,KAAKN,OAAL,CAAaG,CAAb,CAAf;;QAEA,IAAIF,QAAQ,CAACM,KAAb,EAAoB;UAClB,MAAM,KAAKC,2BAAL,CAAiC,KAAKP,QAAtC,EAAgDA,QAAQ,CAACM,KAAzD,CAAN;QACD;;QAED,IAAIN,QAAQ,CAACQ,IAAT,IAAiBR,QAAQ,CAACQ,IAAT,CAAcA,IAAd,CAAmBJ,MAAnB,GAA4B,CAAjD,EAAoD;UAClD,KAAKK,WAAL,CAAiBT,QAAQ,CAACQ,IAA1B,EAAgCP,UAAhC,EAA4CI,MAA5C;QACD;;QAED,IAAIL,QAAQ,CAACU,YAAb,EAA2B;UACzB,MAAMA,YAAY,GAAGV,QAAQ,CAACU,YAA9B;UACA,MAAML,MAAM,GAAG,KAAKN,OAAL,CAAaG,CAAb,CAAf;UACA,MAAMS,aAAoB,GAAG,EAA7B;UACA,MAAMC,KAAK,GAAG,IAAI1B,UAAJ,EAAd;UACA0B,KAAK,CAACC,KAAN,GAAcR,MAAM,CAACQ,KAArB;UAEA,KAAKC,cAAL,CAAoBJ,YAApB,EAAkCL,MAAlC,EAA0CM,aAA1C,EAAyDC,KAAzD,EAAgE,EAAhE,EAAoE,CAApE;UACA,KAAKG,cAAL,CAAoBJ,aAApB,EAAmCN,MAAnC;UACA,KAAKW,UAAL,CAAgBL,aAAhB,EAA+BN,MAA/B;;UAEA,KAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGN,aAAa,CAACP,MAAlC,EAA0Ca,CAAC,EAA3C,EAA+C;YAC7ChB,UAAU,CAACiB,IAAX,CAAgBP,aAAa,CAACM,CAAD,CAA7B;UACD;;UAED,IAAIL,KAAK,CAACO,IAAN,CAAWf,MAAX,GAAoB,CAAxB,EAA2B;YACzBH,UAAU,CAACiB,IAAX,CAAgBN,KAAhB;UACD;QACF;MACF;;MAED,OAAO;QAAEQ,IAAI,EAAEnB;MAAR,CAAP;IACD,CA9lByE;;IAAA,KAAtDF,OAAsD,GAAtDA,OAAsD;IAAA,KAAfC,QAAe,GAAfA,SAAe;IACxE,KAAKD,OAAL,GAAeA,OAAf;IACA,KAAKC,QAAL,GAAgBA,SAAhB;EACD;;EAEDqB,cAAc,CAACC,KAAD,EAAajB,MAAb,EAAyCJ,UAAzC,EAA0DsB,KAA1D,EAAsE;IAClF,IAAIC,SAAJ;;IAEA,KAAK,IAAIP,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGZ,MAAM,CAACoB,OAAP,CAAgBrB,MAApC,EAA4Ca,CAAC,EAA7C,EAAiD;MAC/C,MAAMS,MAAM,GAAGrB,MAAM,CAACoB,OAAP,CAAgBR,CAAhB,CAAf;;MACA,IAAIS,MAAM,CAACC,IAAX,EAAiB;QACf;MACD;;MAED,QAAQD,MAAM,CAACE,IAAf;QACE,KAAK,OAAL;UAAc;YACZJ,SAAS,GAAG;cAAEK,UAAU,EAAE,EAAd;cAAkBH,MAAM,EAAE,OAA1B;cAAmCH,KAAnC;cAA0CV,KAAK,EAAER,MAAM,CAACQ;YAAxD,CAAZ;;YACA,KAAK,IAAIX,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,KAAK,CAACQ,OAAN,CAAc1B,MAAlC,EAA0CF,CAAC,EAA3C,EAA+C;cAC7C,MAAM6B,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc5B,CAAd,CAAf;cACA,MAAM8B,KAAK,GAAGD,MAAM,CAACE,SAArB;cACAT,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0B,CAACc,KAAD,EAAQD,MAAM,CAACG,GAAf,CAA1B;YACD;;YACDjC,UAAU,CAACiB,IAAX,CAAgBM,SAAhB;YACA;UACD;;QACD,KAAK,aAAL;UAAoB;YAClB,IAAIF,KAAK,CAACQ,OAAN,CAAc1B,MAAd,KAAyB,CAA7B,EAAgC;cAC9B;YACD;;YAED,MAAM+B,WAAW,GAAGb,KAAK,CAACQ,OAAN,CAAc,CAAd,CAApB;YACA,MAAMM,WAAW,GAAGD,WAAW,CAACT,MAAM,CAACW,EAAR,CAAX,CAAuBxD,MAA3C;;YAEA,KAAK,MAAMyD,cAAX,IAA6BF,WAA7B,EAA0C;cACxCZ,SAAS,GAAG;gBACVK,UAAU,EAAE,EADF;gBAEVH,MAAM,EAAE,MAAMY,cAFJ;gBAGVf,KAAK,EAAEA,KAHG;gBAIVgB,KAAK,EAAEb,MAAM,CAACa,KAJJ;gBAKV1B,KAAK,EAAER,MAAM,CAACQ;cALJ,CAAZ;;cAQA,KAAK,IAAIX,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,KAAK,CAACQ,OAAN,CAAc1B,MAAlC,EAA0CF,CAAC,EAA3C,EAA+C;gBAC7C,MAAM6B,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc5B,CAAd,CAAf;gBACA,MAAMrB,MAAM,GAAGkD,MAAM,CAACL,MAAM,CAACW,EAAR,CAAN,CAAkBxD,MAAjC;gBACA2C,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0B,CAACrC,MAAM,CAACyD,cAAD,CAAP,EAAyBP,MAAM,CAACG,GAAhC,CAA1B;cACD;;cACDjC,UAAU,CAACiB,IAAX,CAAgBM,SAAhB;YACD;;YAED;UACD;;QACD,KAAK,gBAAL;UAAuB;YACrB,KAAK,MAAMgB,QAAX,IAAuBd,MAAM,CAACe,IAA9B,EAAoC;cAClC,IAAI,CAACf,MAAM,CAACe,IAAP,CAAYD,QAAZ,CAAL,EAAoD;gBAClD;cACD;;cAEDhB,SAAS,GAAG;gBACVK,UAAU,EAAE,EADF;gBAEVH,MAAM,EAAEc,QAFE;gBAGVjB,KAAK,EAAEA,KAHG;gBAIVgB,KAAK,EAAEb,MAAM,CAACa,KAJJ;gBAKV1B,KAAK,EAAER,MAAM,CAACQ;cALJ,CAAZ;;cAQA,KAAK,IAAIX,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,KAAK,CAACQ,OAAN,CAAc1B,MAAlC,EAA0CF,CAAC,EAA3C,EAA+C;gBAC7C,MAAM6B,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc5B,CAAd,CAAf;gBACA,MAAMwC,KAAK,GAAGX,MAAM,CAACL,MAAM,CAACW,EAAR,CAApB,CAF6C,CAI7C;;gBACAK,KAAK,CAACC,0BAAN,GAAmCD,KAAK,CAACE,oBAAN,CAA2BC,KAA9D;gBACAH,KAAK,CAACI,0BAAN,GAAmCJ,KAAK,CAACE,oBAAN,CAA2BG,KAA9D;gBAEAvB,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0B,CAACwB,KAAK,CAACF,QAAD,CAAN,EAAkBT,MAAM,CAACG,GAAzB,CAA1B;cACD;;cAEDjC,UAAU,CAACiB,IAAX,CAAgBM,SAAhB;YACD;;YAED;UACD;;QACD,KAAK,aAAL;UAAoB;YAAA;;YAClB,wBAAIE,MAAM,CAACsB,QAAX,sEAAI,iBAAiBvB,OAArB,kDAAI,sBAA0BrB,MAA9B,EAAsC;cACpC,KAAK,MAAM6C,WAAX,yBAA0BvB,MAAM,CAACsB,QAAjC,sDAA0B,kBAAiBvB,OAA3C,EAAoD;gBAAA;;gBAClDD,SAAS,GAAG;kBACVK,UAAU,EAAE,EADF;kBAEVH,MAAM,EAAEA,MAAM,CAACE,IAFL;kBAGVL,KAAK,EAAEA,KAHG;kBAIVV,KAAK,EAAER,MAAM,CAACQ,KAJJ;kBAKV0B,KAAK,EAAEU;gBALG,CAAZ;;gBAOA,KAAK,IAAI/C,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,KAAK,CAACQ,OAAN,CAAc1B,MAAlC,EAA0CF,CAAC,EAA3C,EAA+C;kBAC7C,MAAM6B,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc5B,CAAd,CAAf;kBACA,MAAMwC,KAAK,GAAGX,MAAM,CAACL,MAAM,CAACW,EAAR,CAApB;kBACA,MAAMxD,MAAM,GAAG6D,KAAK,CAACQ,GAAN,CAAUvE,GAAV,CAAewE,GAAD,IAAS;oBACpC,IAAIA,GAAG,CAAC1B,OAAJ,CAAYwB,WAAZ,CAAJ,EAA8B;sBAC5B,OAAOE,GAAG,CAAC1B,OAAJ,CAAYwB,WAAZ,CAAP;oBACD;;oBACD,OAAO,IAAP;kBACD,CALc,CAAf;kBAMA,MAAMG,KAAK,GAAG,CAACvE,MAAM,CAACA,MAAM,CAACuB,MAAP,GAAgB,CAAjB,CAAP,EAA4B2B,MAAM,CAACG,GAAnC,CAAd;kBACAV,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0BkC,KAA1B;gBACD;;gBACDnD,UAAU,CAACiB,IAAX,CAAgBM,SAAhB;cACD;YACF;;YACD;UACD;;QACD;UAAS;YACPA,SAAS,GAAG;cACVK,UAAU,EAAE,EADF;cAEVH,MAAM,EAAEA,MAAM,CAACE,IAFL;cAGVyB,QAAQ,EAAE3B,MAAM,CAACW,EAHP;cAIVd,KAAK,EAAEA,KAJG;cAKVV,KAAK,EAAER,MAAM,CAACQ;YALJ,CAAZ;;YAQA,IAAIzB,4BAA4B,CAACsC,MAAD,CAAhC,EAA0C;cACxCF,SAAS,CAACe,KAAV,GAAkBb,MAAM,CAACa,KAAzB;YACD;;YAED,KAAK,IAAIrC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,KAAK,CAACQ,OAAN,CAAc1B,MAAlC,EAA0CF,CAAC,EAA3C,EAA+C;cAC7C,MAAM6B,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc5B,CAAd,CAAf;cACA,MAAM8B,KAAK,GAAGD,MAAM,CAACL,MAAM,CAACW,EAAR,CAApB;;cAEA,IAAIL,KAAK,KAAKsB,SAAd,EAAyB;gBACvB,IAAItB,KAAK,CAACuB,gBAAV,EAA4B;kBAC1B/B,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0B,CAACc,KAAK,CAACuB,gBAAP,EAAyBxB,MAAM,CAACG,GAAhC,CAA1B;gBACD,CAFD,MAEO;kBACLV,SAAS,CAACK,UAAV,CAAqBX,IAArB,CAA0B,CAACc,KAAK,CAACA,KAAP,EAAcD,MAAM,CAACG,GAArB,CAA1B;gBACD;cACF;YACF;;YACDjC,UAAU,CAACiB,IAAX,CAAgBM,SAAhB;YACA;UACD;MA1HH;IA4HD;EACF;;EAEDgC,sBAAsB,CACpBlC,KADoB,EAEpBmC,MAFoB,EAGpBpD,MAHoB,EAIpBO,KAJoB,EAKpBW,KALoB,EAMpB;IACA;IACA,IAAIX,KAAK,CAAC8C,OAAN,CAActD,MAAd,KAAyB,CAA7B,EAAgC;MAC9B,KAAK,MAAMuD,OAAX,IAAsBjF,IAAI,CAAC6C,KAAD,CAA1B,EAAmC;QACjCX,KAAK,CAACgD,SAAN,CAAgB;UAAEC,IAAI,EAAEF,OAAR;UAAiBG,UAAU,EAAE;QAA7B,CAAhB;MACD;;MACDlD,KAAK,CAACgD,SAAN,CAAgB;QAAEC,IAAI,EAAEJ,MAAM,CAAClB,KAAf;QAAsBuB,UAAU,EAAE;MAAlC,CAAhB;IACD,CAPD,CASA;;;IACA,MAAMC,cAAc,GAAG,CAAClF,MAAD,EAAgBmF,UAAhB,EAAoChC,KAApC,KAAmD;MACxEpB,KAAK,CAACgD,SAAN,CAAgB;QAAEC,IAAI,EAAEG;MAAR,CAAhB;MACAnF,MAAM,CAACqC,IAAP,CAAYc,KAAZ;IACD,CAHD;;IAIA,MAAMF,OAAO,GAAGrD,OAAO,CAAC6C,KAAK,CAACQ,OAAP,CAAP,GAAyBR,KAAK,CAACQ,OAA/B,GAAyC,CAACR,KAAK,CAACQ,OAAP,CAAzD;;IACA,KAAK,MAAMC,MAAX,IAAqBD,OAArB,EAA8B;MAC5B,MAAMjD,MAAM,GAAG,EAAf;;MAEA,KAAK,MAAMoF,UAAX,IAAyBnF,OAAO,CAACyC,KAAD,CAAhC,EAAyC;QACvC1C,MAAM,CAACqC,IAAP,CAAY+C,UAAZ;MACD,CAL2B,CAO5B;;;MACApF,MAAM,CAACqC,IAAP,CAAYa,MAAM,CAACG,GAAnB;;MAEA,KAAK,MAAMR,MAAX,IAAqBrB,MAAM,CAACoB,OAAP,IAAkB,EAAvC,EAA2C;QACzC,QAAQC,MAAM,CAACE,IAAf;UACE,KAAK,OAAL;YAAc;cACZmC,cAAc,CAAClF,MAAD,EAAS,KAAKqF,aAAL,CAAmBxC,MAAM,CAACE,IAA1B,CAAT,EAA0CG,MAAM,CAACE,SAAjD,CAAd;cACA;YACD;;UACD,KAAK,gBAAL;YAAuB;cACrB,KAAK,MAAMO,QAAX,IAAuBd,MAAM,CAACe,IAA9B,EAAoC;gBAClC,IAAI,CAACf,MAAM,CAACe,IAAP,CAAYD,QAAZ,CAAL,EAAoD;kBAClD;gBACD;;gBAED,MAAME,KAAK,GAAGX,MAAM,CAACL,MAAM,CAACW,EAAR,CAApB,CALkC,CAMlC;;gBACAK,KAAK,CAACC,0BAAN,GAAmCD,KAAK,CAACE,oBAAN,CAA2BC,KAA9D;gBACAH,KAAK,CAACI,0BAAN,GAAmCJ,KAAK,CAACE,oBAAN,CAA2BG,KAA9D;gBAEAgB,cAAc,CAAClF,MAAD,EAAS,KAAKqF,aAAL,CAAmB1B,QAAnB,CAAT,EAA+DE,KAAK,CAACF,QAAD,CAApE,CAAd;cACD;;cACD;YACD;;UACD,KAAK,aAAL;YAAoB;cAClB,MAAMJ,WAAW,GAAGL,MAAM,CAACL,MAAM,CAACW,EAAR,CAAN,CAAkBxD,MAAtC;;cAEA,KAAK,MAAMyD,cAAX,IAA6BF,WAA7B,EAA0C;gBACxC2B,cAAc,CAAClF,MAAD,EAAU,IAAGyD,cAAe,IAAGZ,MAAM,CAACa,KAAM,EAA5C,EAA+CH,WAAW,CAACE,cAAD,CAA1D,CAAd;cACD;;cACD;YACD;;UACD,KAAK,aAAL;YAAoB;cAAA;;cAClB,MAAM6B,QAAQ,GAAG,KAAKD,aAAL,CAAmBxC,MAAM,CAACE,IAA1B,CAAjB;;cAEA,yBAAIF,MAAM,CAACsB,QAAX,8CAAI,kBAAiBvB,OAArB,EAA8B;gBAC5B,KAAK,MAAMwB,WAAX,IAA0BvB,MAAM,CAACsB,QAAP,CAAgBvB,OAA1C,EAAmD;kBACjD;kBACA,MAAMuC,UAAU,GAAGtC,MAAM,CAACsB,QAAP,CAAgBvB,OAAhB,CAAwBrB,MAAxB,GAAiC,CAAjC,GAAsC,GAAE+D,QAAS,IAAGlB,WAAY,EAAhE,GAAoEkB,QAAvF;kBAEA,MAAMzB,KAAK,GAAGX,MAAM,CAACL,MAAM,CAACW,EAAR,CAApB,CAJiD,CAMjD;;kBACA0B,cAAc,CAAClF,MAAD,EAASmF,UAAT,EAAqBtB,KAAK,CAACQ,GAAN,CAAU,CAAV,EAAazB,OAAb,CAAqBwB,WAArB,CAArB,CAAd;gBACD;cACF;;cAED;YACD;;UACD;YAAS;cACP,IAAIe,UAAU,GAAG,KAAKE,aAAL,CAAmBxC,MAAM,CAACE,IAA1B,CAAjB;cACA,MAAMwC,YAAY,GAAG9F,MAAM,CAAC+B,MAAM,CAACoB,OAAR,EAAiB;gBAAEG,IAAI,EAAEF,MAAM,CAACE;cAAf,CAAjB,CAA3B,CAFO,CAIP;;cACA,IAAIwC,YAAY,CAAChE,MAAb,GAAsB,CAA1B,EAA6B;gBAC3B,IAAIhB,4BAA4B,CAACsC,MAAD,CAAhC,EAA0C;kBACxCsC,UAAU,IAAI,MAAMtC,MAAM,CAACa,KAA3B;gBACD;;gBAED,IAAIb,MAAM,CAACE,IAAP,KAAgB,eAApB,EAAqC;kBACnC;kBACAoC,UAAU,GAAGxE,cAAc,CAACkC,MAAD,CAA3B;gBACD;cACF;;cAEDqC,cAAc,CAAClF,MAAD,EAASmF,UAAT,EAAqBjC,MAAM,CAACL,MAAM,CAACW,EAAR,CAAN,CAAkBL,KAAvC,CAAd;cACA;YACD;QA/DH;MAiED;;MAEDpB,KAAK,CAACO,IAAN,CAAWD,IAAX,CAAgBrC,MAAhB;IACD;EACF,CAnP0B,CAqP3B;EACA;;;EACAiC,cAAc,CAACuD,IAAD,EAAYhE,MAAZ,EAAwCJ,UAAxC,EAAyDW,KAAzD,EAA4EW,KAA5E,EAAwF+C,KAAxF,EAAuG;IACnH,IAAIvC,MAAJ,EAAY0B,MAAZ,EAAyBnC,KAAzB,EAAgCiD,KAAhC;IACA,MAAMC,QAAQ,GAAGnE,MAAM,CAACoE,UAAP,CAAmBrE,MAAnB,GAA4B,CAA7C;;IAEA,KAAKmE,KAAL,IAAcF,IAAd,EAAoB;MAClBZ,MAAM,GAAGlF,IAAI,CAAC8B,MAAM,CAACoE,UAAR,EAAoB;QAAEpC,EAAE,EAAEkC;MAAN,CAApB,CAAb;MACAjD,KAAK,GAAG+C,IAAI,CAACE,KAAD,CAAZ;;MAEA,IAAI,CAACd,MAAL,EAAa;QACX;MACD;;MAED,IAAIa,KAAK,KAAKE,QAAd,EAAwB;QACtB,IAAIf,MAAM,CAAC7B,IAAP,KAAgB,gBAApB,EAAsC;UACpC,KAAKP,cAAL,CAAoBC,KAApB,EAA2BjB,MAA3B,EAAmCJ,UAAnC,EAA+CsB,KAA/C;QACD,CAFD,MAEO;UACL,KAAKiC,sBAAL,CAA4BlC,KAA5B,EAAmCmC,MAAnC,EAA2CpD,MAA3C,EAAmDO,KAAnD,EAA0DW,KAA1D;QACD;MACF,CAND,MAMO;QACL,KAAK,MAAMmD,SAAX,IAAwBpD,KAAK,CAACQ,OAA9B,EAAuC;UACrCC,MAAM,GAAGT,KAAK,CAACQ,OAAN,CAAc4C,SAAd,CAAT;UACAnD,KAAK,GAAGlD,KAAK,CAACkD,KAAD,CAAb;;UACA,IAAIQ,MAAM,CAACG,GAAP,KAAe,KAAK,CAAxB,EAA2B;YACzBX,KAAK,CAACkC,MAAM,CAAClB,KAAR,CAAL,GAAsBR,MAAM,CAACG,GAA7B;UACD,CAFD,MAEO;YACLX,KAAK,CAAC,QAAD,CAAL,GAAkBmD,SAAlB;UACD;;UACD,IAAI3C,MAAM,CAAC4C,aAAX,EAA0B;YACxBpD,KAAK,CAACkC,MAAM,CAAClB,KAAR,CAAL,GAAsBR,MAAM,CAAC4C,aAA7B;UACD;;UACD,KAAK7D,cAAL,CAAoBiB,MAApB,EAA4B1B,MAA5B,EAAoCJ,UAApC,EAAgDW,KAAhD,EAAuDW,KAAvD,EAA8D+C,KAAK,GAAG,CAAtE;QACD;MACF;IACF;EACF;;EAEOJ,aAAa,CAACxC,MAAD,EAAyB;IAC5C,MAAMkD,SAAS,GAAGC,MAAM,CAACC,OAAP,CAAezF,uBAAf,EACff,MADe,CACR,CAAC,CAAC4D,GAAD,CAAD,KAAWA,GAAG,KAAKR,MADX,EAEf/C,GAFe,CAEX,CAAC,CAACoG,CAAD,EAAI/C,KAAJ,CAAD,KAAgBA,KAFL,EAEY,CAFZ,CAAlB;;IAIA,IAAI4C,SAAJ,EAAe;MACb,OAAOA,SAAS,CAACI,KAAjB;IACD;;IAED,MAAMC,YAAY,GAAG3F,QAAQ,CAAC4F,aAAT,CAAuB3G,IAAvB,CAA6B4G,CAAD,IAAOA,CAAC,CAACnD,KAAF,KAAYN,MAA/C,CAArB;;IACA,IAAIuD,YAAJ,EAAkB;MAChB,OAAOA,YAAY,CAACD,KAApB;IACD;;IAED,OAAOtD,MAAP;EACD;;EAEO0D,aAAa,CAACC,MAAD,EAAchF,MAAd,EAA0CiF,KAA1C,EAA0D;IAC7E,IAAItB,UAAU,GAAG,KAAKE,aAAL,CAAmBmB,MAAM,CAAC3D,MAA1B,CAAjB;;IAEA,IAAIrB,MAAM,CAACkF,KAAX,EAAkB;MAChB,MAAMC,KAAK,GAAG,qBAAd;MAEA,OAAOnF,MAAM,CAACkF,KAAP,CAAaE,OAAb,CAAqBD,KAArB,EAA4B,CAACE,KAAD,EAAaC,EAAb,EAAsBC,EAAtB,KAAkC;QACnE,MAAMC,KAAK,GAAGF,EAAE,IAAIC,EAApB;;QAEA,IAAIC,KAAK,CAACC,OAAN,CAAc,OAAd,MAA2B,CAA/B,EAAkC;UAChC,OAAOT,MAAM,CAAC9D,KAAP,CAAasE,KAAK,CAACE,SAAN,CAAgB,CAAhB,CAAb,CAAP;QACD;;QACD,IAAIV,MAAM,CAAC9D,KAAP,CAAasE,KAAb,MAAwB,KAAK,CAAjC,EAAoC;UAClC,OAAOR,MAAM,CAAC9D,KAAP,CAAasE,KAAb,CAAP;QACD;;QACD,IAAIA,KAAK,KAAK,QAAd,EAAwB;UACtB,OAAO7B,UAAP;QACD;;QACD,IAAI6B,KAAK,KAAK,OAAd,EAAuB;UACrB,OAAOR,MAAM,CAAC9C,KAAP,IAAgB,EAAvB;QACD;;QAED,OAAOmD,KAAP;MACD,CAjBM,CAAP;IAkBD;;IAED,IAAIpG,QAAQ,CAAC0G,aAAT,CAAuBX,MAAM,CAAC3D,MAA9B,CAAJ,EAA2C;MACzC,IAAI2D,MAAM,CAAC3D,MAAP,IAAiBpC,QAAQ,CAAC2G,oCAAT,CAA8CZ,MAAM,CAAC3D,MAArD,CAArB,EAAmF;QACjF,MAAMwE,GAAQ,GAAG3H,IAAI,CAAC8B,MAAM,CAACoB,OAAR,EAAiB;UAAEY,EAAE,EAAEgD,MAAM,CAAChC;QAAb,CAAjB,CAArB;;QACA,IAAI6C,GAAG,IAAIA,GAAG,CAAClD,QAAJ,CAAamD,MAAxB,EAAgC;UAC9BnC,UAAU,GAAGxE,cAAc,CAAC0G,GAAD,CAA3B;;UAEA,KAAK,MAAME,EAAX,IAAiBF,GAAG,CAACG,iBAArB,EAAwC;YACtC,MAAMC,UAAe,GAAG/H,IAAI,CAAC8B,MAAM,CAACoB,OAAR,EAAiB;cAAEY,EAAE,EAAE+D,EAAE,CAACG;YAAT,CAAjB,CAA5B;;YACA,IAAID,UAAJ,EAAgB;cACdtC,UAAU,GAAGA,UAAU,CAACyB,OAAX,CAAmB,YAAYW,EAAE,CAACI,IAAlC,EAAwCjH,cAAc,CAAC+G,UAAD,CAAtD,CAAb;YACD;UACF;QACF,CATD,MASO;UACLtC,UAAU,GAAG,OAAb;QACD;MACF,CAdD,MAcO;QACL,MAAMsC,UAAe,GAAG/H,IAAI,CAAC8B,MAAM,CAACoB,OAAR,EAAiB;UAAEY,EAAE,EAAEgD,MAAM,CAAC9C;QAAb,CAAjB,CAA5B;;QACA,IAAI+D,UAAJ,EAAgB;UACdtC,UAAU,IAAI,MAAMzE,cAAc,CAAC+G,UAAD,CAAlC;QACD,CAFD,MAEO;UACLtC,UAAU,GAAG,OAAb;QACD;MACF;IACF,CAvBD,MAuBO,IAAIqB,MAAM,CAAC9C,KAAX,EAAkB;MACvByB,UAAU,IAAI,MAAMqB,MAAM,CAAC9C,KAA3B;IACD;;IAED,MAAMkE,QAAQ,GAAG/H,IAAI,CAAC2G,MAAM,CAAC9D,KAAR,CAArB;;IACA,IAAIkF,QAAQ,CAACrG,MAAT,KAAoB,CAAxB,EAA2B;MACzB,OAAO4D,UAAP;IACD;;IAED,IAAIwC,IAAI,GAAG,EAAX;;IACA,KAAK,MAAME,QAAX,IAAuBrB,MAAM,CAAC9D,KAA9B,EAAqC;MACnCiF,IAAI,IAAInB,MAAM,CAAC9D,KAAP,CAAamF,QAAb,IAAyB,GAAjC;IACD;;IAED,IAAIpB,KAAJ,EAAW;MACT,OAAOkB,IAAI,CAACG,IAAL,KAAc,GAAd,GAAoB3C,UAA3B;IACD;;IAED,OAAOwC,IAAI,CAACG,IAAL,EAAP;EACD;;EAED3F,UAAU,CAACf,UAAD,EAAkBI,MAAlB,EAA8C;IAAA;;IACtD,MAAMuG,eAAe,GAAGhI,IAAI,CAACD,GAAG,CAACsB,UAAD,EAAa,QAAb,CAAJ,CAAJ,CAAgCG,MAAxD;IACA,MAAMyG,+BAA+B,GAAG,oBACtCxG,MAAM,CAACoB,OAD+B,oDACtC,gBAAgBnD,MAAhB,CAAwBwI,CAAD,IAAOA,CAAC,CAAClF,IAAF,KAAW,aAAzC,CADsC,EAEtCmF,IAFsC,CAEhCD,CAAD;MAAA;;MAAA,OAAO,CAAC,CAAAA,CAAC,SAAD,IAAAA,CAAC,WAAD,2BAAAA,CAAC,CAAE9D,QAAH,mFAAavB,OAAb,4EAAsBrB,MAAtB,KAAgC,CAAjC,IAAsC,CAA7C;IAAA,CAFiC,CAAxC;;IAIA,KAAK,IAAIF,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGD,UAAU,CAACG,MAA/B,EAAuCF,CAAC,EAAxC,EAA4C;MAC1C,MAAMmF,MAAM,GAAGpF,UAAU,CAACC,CAAD,CAAzB;MACAmF,MAAM,CAAChF,MAAP,GAAgB,KAAK+E,aAAL,CAAmBC,MAAnB,EAA2BhF,MAA3B,EAAmCuG,eAAe,GAAG,CAAlB,IAAuBC,+BAA1D,CAAhB;IACD;EACF;;EAEDpG,WAAW,CAACD,IAAD,EAA+CP,UAA/C,EAAkEI,MAAlE,EAA8F;IACvG,MAAM2G,SAAS,GAAG,OAAOxG,IAAI,CAACyG,KAAZ,KAAsB,QAAtB,GAAiCzG,IAAI,CAACyG,KAAtC,GAA8CzG,IAAI,CAACyG,KAAL,CAAWjF,KAA3E,CADuG,CACrB;;IAElF,MAAMqD,MAAW,GAAG;MAClBhF,MAAM,EAAEA,MAAM,CAACQ,KADG;MAElBe,IAAI,EAAE,MAFY;MAGlBf,KAAK,EAAER,MAAM,CAACQ,KAHI;MAIlBgB,UAAU,EAAE,EAJM;MAKlBoF,KAAK,EAAED,SALW;MAMlBlD,UAAU,EAAE;IANM,CAApB;IAQA,IAAI4C,QAAJ,EAAcvD,GAAd,EAAmB+D,GAAnB,EAA6BhH,CAA7B;;IAEA,KAAKA,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGM,IAAI,CAACA,IAAL,CAAUJ,MAA1B,EAAkCF,CAAC,EAAnC,EAAuC;MACrCiD,GAAG,GAAG3C,IAAI,CAACA,IAAL,CAAUN,CAAV,CAAN;MACAgH,GAAG,GAAG;QACJC,GAAG,EAAEhE,GAAG,CAACgE,GADL;QAEJC,KAAK,EAAEjE,GAAG,CAACiE,KAFP;QAGJC,MAAM,EAAElE,GAAG,CAACkE,MAHR;QAIJC,IAAI,EAAEnE,GAAG,CAACmE,IAJN;QAKJC,SAAS,EAAEpE,GAAG,CAACoE;MALX,CAAN;;MAQA,IAAIpE,GAAG,CAACqE,OAAR,EAAiB;QACf,KAAKd,QAAL,IAAiBvD,GAAG,CAACqE,OAArB,EAA8B;UAC5BN,GAAG,CAACR,QAAD,CAAH,GAAgBvD,GAAG,CAACqE,OAAJ,CAAYd,QAAZ,CAAhB;QACD;MACF;;MAED,KAAKA,QAAL,IAAiBvD,GAAG,CAACsE,MAArB,EAA6B;QAC3BP,GAAG,CAACR,QAAD,CAAH,GAAgBvD,GAAG,CAACsE,MAAJ,CAAWf,QAAX,CAAhB;MACD;;MACDrB,MAAM,CAACxD,UAAP,CAAkBX,IAAlB,CAAuBgG,GAAvB;IACD;;IAEDjH,UAAU,CAACiB,IAAX,CAAgBmE,MAAhB;EACD;;EAEDtE,cAAc,CAACL,YAAD,EAAoBL,MAApB,EAAgD;IAC5D,MAAMqH,SAAc,GAAGnJ,IAAI,CAAC8B,MAAM,CAACoE,UAAR,EAAoB;MAAE7C,IAAI,EAAE;IAAR,CAApB,CAA3B;IAEA,MAAM+F,sBAAsB,GAAGD,SAAS,IAAIA,SAAS,CAAC1E,QAAvB,IAAmC0E,SAAS,CAAC1E,QAAV,CAAmB4E,SAArF;;IACA,IAAID,sBAAJ,EAA4B;MAC1B,MAAMhB,IAAI,GAAGe,SAAS,CAAC1E,QAAV,CAAmB4E,SAAhC;;MACA,KAAK,MAAMC,IAAX,IAAmBnH,YAAnB,EAAiC;QAC/B,MAAMoH,MAAM,GAAGpH,YAAY,CAACmH,IAAD,CAA3B;;QACA,IAAIC,MAAM,CAACjG,UAAP,CAAkBzB,MAAlB,GAA2BuG,IAAI,GAAG,CAAtC,EAAyC;UACvCmB,MAAM,CAACjG,UAAP,GAAoBiG,MAAM,CAACjG,UAAP,CAAkBkG,KAAlB,CAAwBpB,IAAxB,EAA8BmB,MAAM,CAACjG,UAAP,CAAkBzB,MAAlB,GAA2BuG,IAAzD,CAApB;QACD;MACF;IACF;EACF;;EAEDpG,2BAA2B,CAACP,QAAD,EAAgBgI,GAAhB,EAA0B;IACnD,MAAMC,MAAW,GAAG,EAApB;IACAA,MAAM,CAAC7G,IAAP,GAAc8G,IAAI,CAACC,SAAL,CAAeH,GAAf,EAAoB,IAApB,EAA0B,CAA1B,CAAd;;IACA,IAAIA,GAAG,CAACI,UAAJ,IAAkBJ,GAAG,CAACI,UAAJ,CAAehI,MAAf,GAAwB,CAA1C,IAA+C4H,GAAG,CAACI,UAAJ,CAAe,CAAf,EAAkBC,MAArE,EAA6E;MAC3EJ,MAAM,CAACK,OAAP,GAAiBN,GAAG,CAACI,UAAJ,CAAe,CAAf,EAAkBC,MAAnC;IACD,CAFD,MAEO;MACLJ,MAAM,CAACK,OAAP,GAAiBN,GAAG,CAACK,MAAJ,IAAc,gCAA/B;IACD;;IAED,IAAIrI,QAAQ,CAACuI,QAAb,EAAuB;MACrBN,MAAM,CAACO,MAAP,GAAgBxI,QAAQ,CAACuI,QAAzB;IACD;;IAED,OAAON,MAAP;EACD;;EAEDQ,aAAa,GAAG;IACd,IAAI,KAAK1I,OAAL,CAAagH,IAAb,CAAmB1G,MAAD,IAAYf,QAAQ,CAACoJ,eAAT,CAAyBrI,MAAzB,EAAiC,UAAjC,CAA9B,CAAJ,EAAiF;MAC/E,OAAO,KAAKsI,2BAAL,CAAiC,KAAjC,CAAP;IACD;;IACD,OAAO,KAAKC,uBAAL,EAAP;EACD;;EAEDC,OAAO,CAACC,eAAD,EAA2BC,aAA3B,EAAsE;IAC3E,OAAO,KAAKJ,2BAAL,CAAiC,IAAjC,EAAuCG,eAAvC,EAAwDC,aAAxD,CAAP;EACD;;EAEOJ,2BAA2B,CACjCK,aADiC,EAEjCF,eAFiC,EAGjCC,aAHiC,EAId;IACnB,MAAME,SAAsB,GAAG,EAA/B;;IACA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKlJ,QAAL,CAAcG,SAAd,CAAwBC,MAA5C,EAAoD8I,CAAC,EAArD,EAAyD;MACvD,MAAMlJ,QAAQ,GAAG,KAAKA,QAAL,CAAcG,SAAd,CAAwB+I,CAAxB,CAAjB;;MACA,IAAIlJ,QAAQ,CAACM,KAAb,EAAoB;QAClB,MAAM,KAAKC,2BAAL,CAAiC,KAAKP,QAAtC,EAAgDA,QAAQ,CAACM,KAAzD,CAAN;MACD;;MAED,IAAIN,QAAQ,CAACQ,IAAb,EAAmB;QACjB,MAAM;UAAE2I,SAAF;UAAaC;QAAb,IAAsBC,WAAW,CAACrJ,QAAQ,CAACQ,IAAT,CAAcA,IAAf,CAAvC;QAEA,MAAM6E,MAAM,GAAG+D,IAAI,CAAChJ,MAAL,GACXkJ,oBAAoB,CAClBH,SAAS,CAACxK,GAAV,CAAc4K,cAAc,CAACH,IAAD,CAA5B,CADkB,EAElBJ,aAFkB,EAGlB,KAAKjJ,OAAL,CAAa,CAAb,EAAgByJ,SAHE,EAIlBV,eAJkB,EAKlBC,aALkB,CADT,GAQXO,oBAAoB,CAAC,EAAD,EAAKN,aAAL,CARxB;;QAUA,IAAIA,aAAJ,EAAmB;UACjBS,6BAA6B,CAACpE,MAAD,EAAS,MAAT,CAA7B;QACD,CAfgB,CAiBjB;;;QACA,KAAK,MAAM6B,GAAX,IAAkBkC,IAAlB,EAAwB;UACtB,IAAIL,aAAJ,EAAmB;YACjB;YACA;YACA;YACA7B,GAAG,CAAC,OAAD,CAAH,GAAeA,GAAG,CAAC6B,aAAD,CAAlB;UACD,CANqB,CAOtB;UACA;;;UACA,IAAI7B,GAAG,CAACK,SAAR,EAAmB;YAAA;;YACjB;YACA;YACA;YACA;YACA,MAAMmC,wBAAwB,GAAG,IAAIC,MAAJ,CAAWlK,kBAAX,EAA+B,GAA/B,CAAjC;YACA,MAAMmK,kBAAkB,GAAG,IAAID,MAAJ,CAAWlK,kBAAX,CAA3B;YACA,MAAMoK,cAAc,GAAGhF,MAAM,CAACnG,IAAP,CAAYwI,GAAG,CAACK,SAAhB,EACpBuC,OADoB,CACX5H,GAAD,IAAS;cAChB,OAAOgF,GAAG,CAACK,SAAJ,CAAcrF,GAAd,EAAmB4H,OAAnB,CAA4BC,IAAD,IAAkB;gBAClD,MAAMC,cAAc,GAAGD,IAAI,CAACrE,KAAL,CAAWgE,wBAAX,CAAvB;;gBACA,IAAI,CAACM,cAAL,EAAqB;kBACnB,OAAO,EAAP;gBACD;;gBACD,OAAOA,cAAc,CAACrL,GAAf,CAAoBsL,IAAD,IAAU;kBAClC,MAAMC,OAAO,GAAGD,IAAI,CAACvE,KAAL,CAAWkE,kBAAX,CAAhB;kBACA,OAAQM,OAAO,IAAIA,OAAO,CAAC,CAAD,CAAnB,IAA2B,IAAlC;gBACD,CAHM,CAAP;cAID,CATM,CAAP;YAUD,CAZoB,EAapB5L,MAboB,CAabE,QAba,CAAvB,CAPiB,CAqBjB;YACA;;YACA,MAAM2L,WAAW,GAAG,gBAAA9E,MAAM,CAAC5C,IAAP,sDAAa0H,WAAb,GAChBvL,IAAI,CAAC,CAAC,GAAGyG,MAAM,CAAC5C,IAAP,CAAY0H,WAAhB,EAA6B,GAAGN,cAAhC,CAAD,CADY,GAEhB,CAAC,GAAGA,cAAJ,CAFJ;YAGAxE,MAAM,CAAC5C,IAAP,GAAc4C,MAAM,CAAC5C,IAAP,qBAAmB4C,MAAM,CAAC5C,IAA1B;cAAgC0H;YAAhC,KAAgD;cAAEA;YAAF,CAA9D;UACD;;UACD9E,MAAM,CAAC+E,GAAP,CAAWlD,GAAX;QACD;;QAED,MAAM7G,MAAM,GAAG,KAAKN,OAAL,CAAamJ,CAAb,CAAf;QACA7D,MAAM,CAACxE,KAAP,GAAeR,MAAM,CAACQ,KAAtB;QACAoI,SAAS,CAAC/H,IAAV,CAAemE,MAAf;MACD;;MAED,IAAIrF,QAAQ,CAACU,YAAb,EAA2B;QACzB,MAAMA,YAAY,GAAGV,QAAQ,CAACU,YAA9B;QACA,MAAML,MAAM,GAAG,KAAKN,OAAL,CAAamJ,CAAb,CAAf;QACA,MAAMvI,aAAoB,GAAG,EAA7B;QACA,MAAMC,KAAK,GAAG,IAAI1B,UAAJ,EAAd;QAEA,KAAK4B,cAAL,CAAoBJ,YAApB,EAAkCL,MAAlC,EAA0CM,aAA1C,EAAyDC,KAAzD,EAAgE,EAAhE,EAAoE,CAApE;QACA,KAAKG,cAAL,CAAoBJ,aAApB,EAAmCN,MAAnC;QACA,KAAKW,UAAL,CAAgBL,aAAhB,EAA+BN,MAA/B;;QAEA,IAAIO,KAAK,CAACO,IAAN,CAAWf,MAAX,GAAoB,CAAxB,EAA2B;UACzB,MAAMiF,MAAM,GAAGtG,WAAW,CAAC6B,KAAD,CAA1B;UACAyE,MAAM,CAACxE,KAAP,GAAeR,MAAM,CAACQ,KAAtB;UACAoI,SAAS,CAAC/H,IAAV,CAAemE,MAAf;QACD;;QAED,KAAK,IAAIpE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGN,aAAa,CAACP,MAAlC,EAA0Ca,CAAC,EAA3C,EAA+C;UAC7C,IAAIoE,MAAM,GAAGtG,WAAW,CAAC4B,aAAa,CAACM,CAAD,CAAd,CAAxB,CAD6C,CAG7C;;UACA,IAAI+H,aAAJ,EAAmB;YACjBS,6BAA6B,CAACpE,MAAD,EAAS,OAAT,CAA7B;UACD;;UAEDA,MAAM,CAACxE,KAAP,GAAeR,MAAM,CAACQ,KAAtB;UACAoI,SAAS,CAAC/H,IAAV,CAAemE,MAAf;QACD;MACF;IACF;;IAED,OAAO;MAAEjE,IAAI,EAAE6H;IAAR,CAAP;EACD;;AAxjB0B;;AA2mB7B;AACA;AACA;AACA;AACA;AACA;AACA,MAAMI,WAAW,GAAI7I,IAAD,IAA4E;EAC9F,MAAM4I,IAAW,GAAG,EAApB,CAD8F,CAE9F;EACA;;EACA,IAAID,SAAmB,GAAG,EAA1B;;EAEA,KAAK,MAAMhG,GAAX,IAAkB3C,IAAlB,EAAwB;IACtB,MAAM6J,SAAS,GAAGlH,GAAG,CAACqE,OAAJ,GAAcrI,OAAO,CAACgE,GAAG,CAACqE,OAAL,CAArB,GAAqC,EAAvD;IACA,MAAMN,GAAG;MACPC,GAAG,EAAEhE,GAAG,CAACgE,GADF;MAEPC,KAAK,EAAEjE,GAAG,CAACiE,KAFJ;MAGPC,MAAM,EAAElE,GAAG,CAACkE,MAHL;MAIPC,IAAI,EAAEnE,GAAG,CAACmE,IAJH;MAKPC,SAAS,EAAEpE,GAAG,CAACoE,SALR;MAMPC,OAAO,oBAAO6C,SAAP;IANA,GAOJA,SAPI,CAAT;;IAUA,KAAK,MAAM3D,QAAX,IAAuB7B,MAAM,CAACnG,IAAP,CAAYwI,GAAZ,CAAvB,EAAyC;MACvC,IAAIiC,SAAS,CAACrD,OAAV,CAAkBY,QAAlB,MAAgC,CAAC,CAArC,EAAwC;QACtCyC,SAAS,CAACjI,IAAV,CAAewF,QAAf;MACD;IACF;;IAED0C,IAAI,CAAClI,IAAL,CAAUgG,GAAV;EACD;;EAEDiC,SAAS,CAAC7B,IAAV;EACA,OAAO;IAAE8B,IAAF;IAAQD;EAAR,CAAP;AACD,CA7BD;AA+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMG,oBAAoB,GAAG,CAC3B/H,KAD2B,EAE3ByH,aAF2B,EAG3BQ,SAH2B,EAI3BV,eAJ2B,EAK3BC,aAL2B,KAMN;EACrB,MAAM1D,MAAM,GAAG,IAAIpG,gBAAJ,CAAqB;IAAEwI,MAAM,EAAE;EAAV,CAArB,CAAf;;EAEA,IAAI+B,SAAJ,EAAe;IACbnE,MAAM,CAACiF,QAAP,CAAgB;MACd9B,MAAM,EAAE;QACN1E,UAAU,EAAE;MADN,CADM;MAId0C,IAAI,EAAEgD,SAJQ;MAKd5H,IAAI,EAAE5C,SAAS,CAACuL;IALF,CAAhB;EAOD;;EAED,IAAIzB,eAAJ,EAAqB;IACnB,MAAM0B,CAAC,GAAGnF,MAAM,CAACiF,QAAP,CAAgB;MACxB9D,IAAI,EAAEsC,eADkB;MAExBlH,IAAI,EAAE5C,SAAS,CAACyL;IAFQ,CAAhB,CAAV;IAIApF,MAAM,CAACqF,SAAP,CAAiBF,CAAjB,EAAqBG,CAAD,IAAY;MAC9B,OAAOA,CAAC,IAAI,EAAZ;IACD,CAFD;EAGD;;EAED,IAAI5B,aAAJ,EAAmB;IACjB,MAAMyB,CAAC,GAAGnF,MAAM,CAACiF,QAAP,CAAgB;MACxB9D,IAAI,EAAE,OADkB;MAExB5E,IAAI,EAAE5C,SAAS,CAACyL;IAFQ,CAAhB,CAAV;IAIApF,MAAM,CAACqF,SAAP,CAAiBF,CAAjB,EAAqBG,CAAD,IAAY;MAC9B,OAAOA,CAAC,IAAI,EAAZ;IACD,CAFD;EAGD;;EAED,MAAMC,UAAU,GAAGvF,MAAM,CAACoC,MAAP,CAAc9I,GAAd,CAAmB4D,KAAD,IAAWA,KAAK,CAACiE,IAAnC,CAAnB;;EAEA,KAAK,MAAM,CAACA,IAAD,EAAO5E,IAAP,CAAX,IAA2BL,KAA3B,EAAkC;IAChC;IACA,IAAIqJ,UAAU,CAACC,QAAX,CAAoBrE,IAApB,CAAJ,EAA+B;MAC7B;IACD,CAJ+B,CAKhC;;;IACA,IAAI,CAACwC,aAAD,IAAkBxC,IAAI,KAAK,SAA/B,EAA0C;MACxC;IACD;;IAED,MAAMgE,CAAC,GAAGnF,MAAM,CAACiF,QAAP,CAAgB;MACxB9B,MAAM,EAAE;QACN1E,UAAU,EAAE;MADN,CADgB;MAIxB0C,IAJwB;MAKxB5E;IALwB,CAAhB,CAAV;IAOAyD,MAAM,CAACqF,SAAP,CAAiBF,CAAjB,EAAqBG,CAAD,IAAY;MAC9B,OAAOA,CAAC,IAAI,EAAZ;IACD,CAFD;EAGD;;EAED,OAAOtF,MAAP;AACD,CAhED;;AAkEA,MAAMoE,6BAA6B,GAAG,CAACpE,MAAD,EAAczD,IAAd,KAAmD;EACvF,IAAIkJ,CAAC,GAAGzF,MAAR;EACAyF,CAAC,CAACrI,IAAF,GACKqI,CAAC,CAACrI,IAAF,CAAOsI,0BAAP,GAAoCnJ,IADzC,GAEKkJ,CAAC,CAACrI,IAAF,GAAS;IACRsI,0BAA0B,EAAEnJ;EADpB,CAFd;AAKD,CAPD;;AASA,MAAM2H,cAAc,GACjBH,IAAD,IACC1C,QAAD;EAAA;;EAAA,OACE,CAACA,QAAD,EAAWsE,SAAS,eAAC5B,IAAI,CAAC7K,IAAL,CAAW2I,GAAD,IAASA,GAAG,CAACR,QAAD,CAAH,KAAkBpD,SAArC,CAAD,+CAAC,WAAkDoD,QAAlD,CAAD,CAApB,CADF;AAAA,CAFF;AAKA;AACA;AACA;AACA;;;AACA,MAAMsE,SAAS,GAAIhJ,KAAD,IAA+B;EAC/C,QAAQ,OAAOA,KAAf;IACE,KAAK,QAAL;MACE,OAAOhD,SAAS,CAACiM,MAAjB;;IACF,KAAK,QAAL;MACE,OAAOjM,SAAS,CAACyL,MAAjB;;IACF;MACE,OAAOzL,SAAS,CAACkM,KAAjB;EANJ;AAQD,CATD"},"metadata":{},"sourceType":"module"}